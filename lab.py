# -*- coding: utf-8 -*-
"""lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16B_u0hmpJLedaiP962wmeoWfB03K4DE7

# Bilibili视频网站排行榜评分的线性回归分析

Bilibili（哔哩哔哩）是当下最热门的视频播放网站，人们在该网站对视频进行浏览，会根据自己喜好对视频进行点赞、投币、收藏、分享、回复等操作，Bilibili同时还有一个排行榜机制，记录了近期比较热门的视频，并给出了一个评分，排行榜的排序规则即根据该评分，本文将根据这些排行榜视频的各项数据，进行线性回归分析，结合实际情况找出对评分影响最大的数据。

Bilibili提供了获取排行榜数据的API，因此我们可以利用该API获取实时的排行榜数据，获取的数据为json格式，经过解析，已将数据保存至Bilibili.csv文件中。

本文的思路即为多元线性回归，在统计学中，线性回归（linear regression）是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归（multivariable linear regression）。

完成了对各个自变量权重的计算，找出了对评分影响权重最高的因素，并得到了验证。

在哔哩哔哩官网首页处获取排行榜信息的API，得到为

https://api.bilibili.com/x/web-interface/ranking/v2?rid=0

请求参数为
- rid 分类，0代表全部分类

返回格式为json格式，json中的data字段为视频信息数组。

为了防止请求次数过多增加服务器压力，导致本机IP禁止访问哔哩哔哩，先将请求的response保存到data.txt文件中。

使用python的json包进行解析
```json
{
"aid": 375696064,
"videos": 1,
"tid": 17,
"tname": "单机游戏",
"copyright": 1,
"pic": "http://i0.hdslb.com/bfs/archive/85005893d4c4959ff096d6fb061040e223842bcb.jpg",
"title": "史上最骚魔法师！(第二集)",
"pubdate": 1621566911,
"ctime": 1621566912,
"desc": "本期请到了Warma参与配音！鼓掌！！！！！\n游戏：Darkside Detective\n第一集：BV1M64y1m7gA\n各位如果看得开心，希望三连支持一下！",
"state": 0,
"duration": 658,
"mission_id": 24025,
"rights": {
"bp": 0,
"elec": 0,
"download": 0,
"movie": 0,
"pay": 0,
"hd5": 0,
"no_reprint": 1,
"autoplay": 1,
"ugc_pay": 0,
"is_cooperation": 0,
"ugc_pay_preview": 0,
"no_background": 0
},
"owner": {
"mid": 546195,
"name": "老番茄",
"face": "http://i0.hdslb.com/bfs/face/bc5ca101313d4db223c395d64779e76eb3482d60.jpg"
},
"stat": {
"aid": 375696064,
"view": 1149043,
"danmaku": 7300,
"reply": 3278,
"favorite": 37490,
"coin": 98319,
"share": 1780,
"now_rank": 0,
"his_rank": 1,
"like": 210211,
"dislike": 0
},
"dynamic": "用魔法击败魔法",
"cid": 341808079,
"dimension": {
"width": 1920,
"height": 1080,
"rotate": 0
},
"short_link": "https://b23.tv/BV1jo4y117Vf",
"short_link_v2": "https://b23.tv/BV1jo4y117Vf",
"bvid": "BV1jo4y117Vf",
"score": 2446535
}
```

通过解析json格式文件并整理得到bilibili.csv
"""

# 包引用
import pandas as pd # csv文件读写分析
import numpy as np  # 线性代数
import matplotlib.pyplot as plt # 制图

data = pd.read_csv('./bilibili.csv', index_col='title')

# 评分
score = data['score'] 
# 播放量
view = data['view'] 
# 投币
coins = data['coins']
# 收藏
favor = data['favorite']
# 评论
reply = data['reply']
# 点赞
like = data['like']
# 弹幕数量
danmu = data['danmu']
# 分享次数
share = data['share']

data

"""部分数据展示"""

score

coins

favor

x = [i for i in range(len(score))]
# 获取自变量矩阵
X = data.iloc[:,3:10].values
# 获取因变量矩阵
Y = data.iloc[:,2].values.reshape(-1,1)
# 生成设计矩阵
om = np.ones(X.shape[0]).reshape(-1,1)
X = np.hstack((X, om))

# 绘制图像，按照排名递减绘制，即分数从高到低
plt.xlabel('rank')
plt.ylabel('score')
plt.plot(x, score, 'o')

"""排名-总分图，总分与rank正相关。"""

labels = ['score']
plt.ylabel('score')
plt.boxplot(score, labels = labels, showmeans = True)

"""由箱线图可以得到score数据中，均值大致为120000

中位数大致为900000

使用numpy自带库函数检验
"""

np.mean(score)

np.median(score)

np.var(score)

np.std(score)

plt.xlabel('rank')
plt.ylabel('favorite')
plt.plot(x, favor, 'o')

"""根据排名-收藏图，可以发现，收藏对于排名即总分，有一定的正相关。"""

plt.xlabel('favorite')
labels = ['favorite']
plt.ylabel('favorite')
plt.boxplot(favor, labels = labels, showmeans = True)

"""由箱线图可知，收藏数据集中在[6000, 20000]内，中位数大致为10000，均值为16000"""

np.mean(favor)

np.median(favor)

np.var(favor)

np.std(favor)

plt.xlabel('rank')
plt.ylabel('view')
plt.plot(x, view, 'o')

"""通过排名-播放量图，可以得出播放量与排名在一定程度上为正相关。"""

plt.xlabel('view')
labels = ['view']
plt.ylabel('view')
plt.boxplot(view, labels = labels, showmeans = True)

"""由箱线图可知，播放量数据集中在[600000, 800000]内，中位数大致为600000，均值大致为800000"""

np.mean(view)

np.median(view)

np.var(view)

np.std(view)

plt.xlabel('rank')
plt.ylabel('coins')
plt.plot(x, coins, 'o')

"""通过排名-投币数图，可以得出排名与投币数在一定程度上为正相关。"""

plt.xlabel('coins')
labels = ['coins']
plt.ylabel('coins')
plt.boxplot(coins, labels = labels, showmeans = True)

"""由箱线图可知，投币数据集中在[15000, 30000]内，中位数大致为17000，均值大致为30000"""

np.mean(coins)

np.median(coins)

# 方差
np.var(coins)

# 标准差
np.std(coins)

plt.xlabel('rank')
plt.ylabel('reply')
plt.plot(x, reply, 'o')

"""通过排名-评论数图，可以得出排名与评论数相关性较低。"""

plt.xlabel('reply')
labels = ['reply']
plt.ylabel('reply')
plt.boxplot(reply, labels = labels, showmeans = True)

"""由箱线图可知，评论数据集中在[2500, 4000]内，中位数大致为2500，均值大致为3000"""

np.mean(reply)

np.median(reply)

# 方差
np.var(reply)

# 标准差
np.std(reply)

plt.xlabel('rank')
plt.ylabel('like')
plt.plot(x, like, 'o')

"""通过排名-点赞数图，可以得出排名与点赞数在一定程度上为正相关。"""

plt.xlabel('like')
labels = ['like']
plt.ylabel('like')
plt.boxplot(like, labels = labels, showmeans = True)

"""由箱线图可知，点赞数据集中在[50000, 100000]内，中位数大致为60000,均值大致为80000"""

np.mean(like)

np.median(like)

# 方差
np.var(like)

# 标准差
np.std(like)

plt.xlabel('rank')
plt.ylabel('danmu')
plt.plot(x, danmu, 'o')

"""通过排名-弹幕数图，可以得出排名与弹幕数相关性较低。"""

plt.xlabel('danmu')
labels = ['danmu']
plt.ylabel('danmu')
plt.boxplot(danmu, labels = labels, showmeans = True)

"""由箱线图可知，弹幕数据集中在[2500, 5000]内，中位数大致为2500，均值大致为5000"""

np.median(danmu)

np.mean(danmu)

# 方差
np.var(danmu)

# 标准差
np.std(danmu)

plt.xlabel('rank')
plt.ylabel('share')
plt.plot(x, share, 'o')

"""通过排名-分享数图，可以得出排名与分享数相关性较低。"""

plt.xlabel('share')
labels = ['share']
plt.ylabel('share')
plt.boxplot(share, labels = labels, showmeans = True)

"""由箱线图可知，分享数据集中在[1000, 6000]内，中位数大致为3000，均值大致为6000"""

np.median(share)

np.mean(share)

# 方差
np.var(share)

# 标准差
np.std(share)

# 计算系数矩阵w-hat
w_hat = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), Y)
# 获取b矩阵
b = w_hat[-1]
# 获取w系数矩阵
w = w_hat[:-1]

w_hat

b

w

"""这里发现w系数矩阵中出现了负值，经检查发现该项目对应的自变量为like和reply，即视频的点赞次数和评论数，这与实际情况是不符的，猜测是因为该自变量对结果的影响过小，导致预测出现了偏差，同时发现弹幕数量对视频评分的影响过大，远超于其他参数，显然与实际生活不符，并且作为对视频质量的估计，弹幕数也的确不能作为一个重要的参数。

因此我们对弹幕数进行剔除重新进行拟合。
"""

data = pd.read_csv('./bilibili.csv', index_col='title')

# 获取自变量矩阵，剔除弹幕数
X = data.iloc[:,[3, 4, 5, 6, 8, 9]].values
# 获取因变量矩阵
Y = data.iloc[:,2].values.reshape(-1,1)
# 生成设计矩阵
om = np.ones(X.shape[0]).reshape(-1,1)
X = np.hstack((X, om))

# 计算系数矩阵w-hat
w_hat = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), Y)
# 获取b矩阵
b = w_hat[-1]
# 获取w系数矩阵
w = w_hat[:-1]

b

w

"""观察发现此时各项参数对于评分的影响已经较为接近正常水平。但是share，视频分享数对于评分的影响仍为负值，依然根据上述猜测，share对于总分的影响过小，导致拟合的结果差，因此再次剔除share字段。"""

# 获取自变量矩阵，剔除弹幕数，分享数
X = data.iloc[:,[3, 4, 5, 6, 9]].values
# 获取因变量矩阵
Y = data.iloc[:,2].values.reshape(-1,1)
# 生成设计矩阵
om = np.ones(X.shape[0]).reshape(-1,1)
X = np.hstack((X, om))

# 计算系数矩阵w-hat
w_hat = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), Y)
# 获取b矩阵
b = w_hat[-1]
# 获取w系数矩阵
w = w_hat[:-1]

X_test = data.iloc[:, [3, 4, 5, 6, 9]].values
Y_predict = np.dot(X_test, w) + b

dic = abs(Y-Y_predict)

sum = 0
for i in range(len(Y)):
  sum += abs(Y[i][0] - Y_predict[i][0])

"""误差的平均值"""

sum/len(Y)

#计算平均平方误差啊
mse = 0
for i in range(len(Y)):
    mse += (Y[i][0] - Y_predict[i][0])**2
mse /= len(Y)

mse

len(Y)

# 计算平均平方误差平方根
rmse = np.sqrt(mse)

rmse

# 计算R^2决定系数
# r^2 = 1 - rss/tss
rss = 0
for i in range(len(Y)):
    rss += (Y[i][0] - Y_predict[i][0])**2

rss

mse*len(Y)

# 计算tss
tss = 0
y_ = 0 # average y
for i in range(len(Y)):
    y_ += Y[i][0]
y_ = y_ / len(Y)
for i in range(len(Y)):
    tss += (Y[i][0] - y_)**2
R2 = 1 - rss/tss

R2

"""通过对R^2决定系数的计算，可以发现模型拟合的效果较为良好。

观察预测值与实际值的差距，发现拟合的趋势基本吻合，但仍有较大的误差
"""

x = [i for i in range(0, len(Y))]
plt.plot(x, Y_predict, 'o')
plt.plot(x, Y)

plt.plot(x, Y_predict, 'o')
plt.plot(x, Y, 'o')

"""从图象中可以看出，预测值的趋势与实际值较为接近。"""

y = [sum/len(Y) for i in range(len(x))]
plt.plot(x, dic, 'o')
plt.plot(x, y)

"""分析得出，该线性模型的拟合误差较为集中，集中在[0, 181348.81788162683]即平均误差之间。

根据权重分析各个数据对总分的影响，可以发现，收藏对于视频总评分的影响占比最高，其次是硬币数，播放数，说明哔哩哔哩对与视频的质量高低评判有一定的综合考量，播放量属于可以由视频制作人通过其他方式刷取，但是收藏量是由用户对于视频质量的高低做出的决定，因而更具代表性，更有说服力。反观实际观看体验中，有些视频制作人会以视频收藏满几万后，更新新一期视频，因为该项对视频的收益影响最大，更能给视频制作人带来实际收益。
"""

w

"""本次线性回归的拟合可以较为准确的判断出各各数据对于视频评分的影响，但是对于视频评分的预测误差较大，但是仍能较准确的判断出视频评分所影响的视频排名，认为有如下原因：
- 数据量过少，导致拟合程度不足
- 评分规则非线形模型，应该更换模型
- 还有其他未考虑的因素

如果要更准确的对视频评分进行预测，应该综合分析数据的特性，或者采用机器学习等更优秀的手段来进行求解和预测，线性回归仍有一定的局限性。
"""